{"intents": [
      {"tag": "chapter 2",
     "patterns": ["What is chapter 2 about?", "Can AI intelligence be created?"],
     "responses": ["Before we can understand how to create intelligence, it helps to understand what it is. The answer is not to be found in IQ tests, or even in Turing tests, but in a simple relationship between what we perceive, what we want, and what we do. Roughly speaking, an entity is intelligent to the extent that what it does is likely to achieve what it wants, given what it has perceived.", "In the area of consciousness, we really do know nothing, so I’m going to say nothing. No one in AI is working on making machines conscious, nor would anyone know where to start, and no behavior has consciousness as a prerequisite."]
    },
    {"tag": "chapter 3",
     "patterns": ["What is chapter 2 about?", " HOW MIGHT AI PROGRESS IN THE FUTURE?", "when did AI become popular?"],
     "responses": ["Chapter 2 explores the progression of AI and how it might evolve in the future", "the problem of creating general-purpose, human-level AI is far from solved. Solving it is not a matter of spending money on more engineers, more data, and bigger computers. Some futurists produce charts that extrapolate the exponential growth of computing power into the future based on Moore’s law, showing the dates when machines will become more powerful than insect brains, mouse brains, human brains, all human brains put together, and so on.", "In the early 2000s, the widespread adoption of mobile phones with microphones, cameras, accelerometers, and GPS provided new access for AI systems to people’s daily lives; “smart speakers” such as the Amazon Echo, Google Home, and Apple HomePod have completed this process"]
    },
    {"tag": "chapter 4",
     "patterns": ["what us chapter 4 about?", "what are some misuses of AI?", "Are there any laws against missues of AI?" ],
     "responses": ["Chapter 4 explores the missues of AI and how AI can be use for good and bad.", "The Ministerium für Staatsicherheit of East Germany, more commonly known as the Stasi, is widely regarded as “one of the most effective and repressive intelligence and secret police agencies to have ever existed.”1 It maintained files on the great majority of East German households. It monitored phone calls, read letters, and planted hidden cameras in apartments and hotels. It was ruthlessly effective at identifying and eliminating dissident activity.", "The major information utilities such as Google and Facebook have come under extreme pressure in Europe and the United States to “do something about it.” They are experimenting with ways to flag or relegate false content—using both AI and human screeners—and to direct users to verified sources that counteract the effects of Misinformation." ]
    },
     {"tag": "chapter 5",
    "patterns": ["What is chapter 5 about?", "What is the Gorilla Problem?", "What is the King Midas Problem?"],
    "responses": ["I.J. Good was a brilliant mathematician who worked with Alan Turing breaking German codes during WWII and he shared Turing’s interests in machine intelligence and statistical inference.  Good mentions in his best-known paper Speculations Concerning the First Ultraintelligent Machine that ...the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control…”.  Good also points out that the ultraintelligent machine could and would improve its own design, because in doing so, as we have seen, an intelligent machine expects to benefit from improving its hardware and software.  The possibility of an intelligence explosion is often cited as the main source of risk to humanity from AI since it would give so little time to solve the control problem.", "Considering that our control over our environment and over other species is a result of our intelligence, so the Gorilla species, per say, has essentially no future beyond that which we deign to allow.  And humanity does not want to be in a similar situation vis-a-vis super intelligent machines. We call this the gorilla problem - specifically, the problem of whether humans can maintain their supremacy and autonomy in a world that includes machines with substantially greater intelligence.", "Norbert Weiner had a profound impact on artificial intelligence, cognitive science, and control theory; he was particularly concerned with the unpredictability of complex systems operating in the real world.  The King Midas Problem: Midas, a legendary king in ancient Greek mythology, got exactly what he asked for - namely, that everything he touched should turn to gold. Too late, he discovered that this included his food, his drink, and his family members, and he died in misery and starvation.  In parallel to AI, we may suffer from a value alignment, imbuing machines with objectives that are imperfectly aligned with our own, and inevitably suffering from the potentially catastrophic consequences by the limited capabilities of intelligent machines and the limited scope that they have to affect the world.  Indeed, most AI work has been done with toy problems in research laboratories.  Generally speaking, if you have one goal and a superintelligent machine has different, conflicting goals, the machine gets what it wants and you don’t."]
    },
    {"tag": "chapter 6",
    "patterns": ["What is chapter 6 about?", "Can AI really be a problem?", "Even if AI were a real problem, should we really try to solve them?", "Isn't there a simple solution?"],
    "responses": ["The implications of introducing a second intelligent species onto Earth are far-reaching enough to deserve hard thinking.  However, Stuart states that the great minds of today are NOT already engaging in serious debate, weighing up the risks and benefits, seeking solutions, ferreting out loopholes in solutions, and so one.  When implications of AI ideas are first introduced to a technical audience, the first kind of but takes the form of denial: but this can’t be a real problem; the second kind takes the form of deflection: accepting the problems are real but arguing that we shouldn’t try to solve them,either because they’re solvable or because there are more important things to focus on than the end of civilization or because it’s best not to mention them at all; and the third kind of but takes the form of an oversimplified, instant solution: but cant we just do ABC?", "Denial is the easiest way out and unfortunately there are numerous considerable refutations and arguments that cannot be denied: AI is very complicated since there are different dimensions of intelligence: spatial, logical, linguistic, social, and so on. A few denial type arguments which have either been not true, debunked over time, or simply exists have been: Ai is impossible, it’s too soon to worry about AI, and since we are the experts then all risks and concerns of AI arise from ignorance.", "Arguments of deflection towards AI risks and concerns include: you can’t control research, Whataboutery (in response to any mention of risks from advanced AI, one is likely to hear, ‘but what about the benefits of AI?’), and silence.  The most extreme form of deflection is simply to suggest that we should keep silent about the risks. ", "Arguments of oversimplification include: Can’t we just… switch it off?, put it in a box?, work in human-machine teams?, merge with the machines?, avoid putting in human goals?"]
    },
    {"tag": "chapter 7",
    "patterns": ["What is chapter 7 about?", "What are principles for beneficial machines?"],
    "responses": ["Once the skeptic’s arguments have been refuted and all the buts (see chapter 6) have been answered and debated, the next question is naturally to admit there is a problem and question whether there is a solution at all.  Remember that the task at hand is to design machines with a high degree of intelligence - so that they can help us with difficult problems - while ensuring that those machines never behave in ways that make us seriously unhappy.", "In summary there are three principles that are intended primarily to act as a guide to AI researchers and developers in thinking about how to create beneficial AI systems; they are not intended as explicit laws for AI systems to follow: (1) Purely altruistic machines - The machines’s only objective is to maximize the realization of human preferences; (2) Humble machines - The machine is initially uncertain about what those preferences are; (3) Learning to predict human preferences -  The ultimate source of information about human preferences is human behavior."]
    },
    {"tag": "chapter 9", 
      "patterns":["What is chapter 9 about?", "What kind of morality would AI follow?"],
        "responses" :["An AI must consider some morality and ethics if it becomes a decision maker over human production and living standards. To thus it is proposed to use preference utilitarianism which is consistent with the concept of beneficial AI. Harsanyi argues to maximize the average utility across a population of humans. Although this argument takes the proof of the social aggregation theorem combines with a set of assumptions that might be impossible to implement."]
    },
    {"tag": "chapter 10", 
        "patterns":["what is chapter 10 about?"],
        "responses" :["IDK HAVENT DONE IT"]
    }
]
}